{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA2_ LS_DS_422_BOW_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "U4S1-TEST",
      "language": "python",
      "name": "u4s1-test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shemaaali/DS-Unit-4-Sprint-1-NLP/blob/main/LS_DS_412_Vector_Representations_Assignment/SA2__LS_DS_422_BOW_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5-Lbt5dSBKG"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Vector Representations\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeNc-14VW26F",
        "outputId": "72d0a30b-2e94-473b-87c7-dc6e6cb33073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Dependencies for the week (instead of conda)\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-29 19:34:00--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]     137  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-29 19:34:00 (7.37 MB/s) - ‘requirements.txt’ saved [137/137]\n",
            "\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 171kB/s \n",
            "\u001b[?25hCollecting pyLDAvis==2.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 47.3MB/s \n",
            "\u001b[?25hCollecting spacy==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 44.9MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/7f/366dcba1ba076a88a50bea732dbc033c0c5bbf7876010e6edc67948579d5/scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 45.5MB/s \n",
            "\u001b[?25hCollecting seaborn==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 50.5MB/s \n",
            "\u001b[?25hCollecting squarify==0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/2b/2e77c35326efec19819cd1d729540d4d235e6c2a3f37658288a363a67da5/squarify-0.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (4.6.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.35.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (50.3.0)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (0.8.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (4.3.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (20.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.2.5)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=66997bca348162eecc363e75419a674dac3598666058dbd8f8fd3dadad24c951\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: gensim, funcy, pyLDAvis, thinc, spacy, scikit-learn, seaborn, squarify\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: seaborn 0.11.0\n",
            "    Uninstalling seaborn-0.11.0:\n",
            "      Successfully uninstalled seaborn-0.11.0\n",
            "Successfully installed funcy-1.15 gensim-3.8.1 pyLDAvis-2.1.2 scikit-learn-0.22.2 seaborn-0.9.0 spacy-2.2.3 squarify-0.4.3 thinc-7.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn",
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U4Wz3gJXKQB",
        "outputId": "88678ed0-2c2d-4326-be14-5c3ad760ec20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg  # Can do lg, takes awhile\n",
        "# Also on Colab, need to restart runtime after this step!"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=3617d465655afdc4f385ef8ec07d5df48f911cde410446164c76fd1fb4a4aa76\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9hwfeojy/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Pq12LoZ1mQ",
        "outputId": "9200b5c8-e38e-4b28-dbd6-26c8760c8ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import html.parser\n",
        "from lxml import html\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7bcmqfGXrFG"
      },
      "source": [
        "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
        "\n",
        "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcYlc1URXhlC",
        "outputId": "69315f8b-425c-4dea-dd76-d04656b5334c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/shemaaali/DS-Unit-4-Sprint-1-NLP/main/module2-vector-representations/data/job_listings.csv\"\n",
        "df = pd.read_csv(url, index_col=0)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description                         title\n",
              "0  b\"<div><div>Job Requirements:</div><ul><li><p>...               Data scientist \n",
              "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...              Data Scientist I\n",
              "2  b'<div><p>As a Data Scientist you will be work...  Data Scientist - Entry Level\n",
              "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...                Data Scientist\n",
              "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...                Data Scientist"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C4xFZNtX1m2"
      },
      "source": [
        "## 2) Use Spacy to tokenize the listings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-V-05DUYd20"
      },
      "source": [
        "# Load the pre-trained statistical model for English\n",
        "import en_core_web_lg\n",
        "\n",
        "# setting up natural language processor and tokenizer\n",
        "nlp = en_core_web_lg.load()\n",
        "\n",
        "tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)\n",
        "\n",
        "# creates stop words\n",
        "STOPWORDS = nlp.Defaults.stop_words.union({' ', ''})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyzDf9ghYK5Y"
      },
      "source": [
        "\n",
        "# makes a copy of df\n",
        "df1 = df.copy()\n",
        "\n",
        "# removes html elements with lxml\n",
        "df1['description'] = df1['description'].apply(lambda x: html.fromstring(x).text_content())\n",
        "\n",
        "# replaces new line charecters with space\n",
        "df1['description'] = df1['description'].apply(lambda x: x.replace('\\\\n', ' '))\n",
        "\n",
        "# removes punctuation with regex\n",
        "df1['description'] = df1['description'].apply(lambda x: re.sub(r'[^a-zA-Z ]', '', x))\n",
        "\n",
        "# removes the b at the start of every string\n",
        "df1['description'] = df1['description'].apply(lambda x: x[1:])\n",
        "\n",
        "# makes all words lowercase\n",
        "df1['description'] = df1['description'].apply(lambda x: x.lower())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijULxckQZSXQ",
        "outputId": "d257bc69-5941-4433-d6e9-7809cb9bbb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>job requirements conceptual understanding in m...</td>\n",
              "      <td>Data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>job description  as a data scientist  you will...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>as a data scientist you will be working on con...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a monthcontractunder the general supervisio...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>location usa xexx multiple locations  years of...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description                         title\n",
              "0  job requirements conceptual understanding in m...               Data scientist \n",
              "1  job description  as a data scientist  you will...              Data Scientist I\n",
              "2  as a data scientist you will be working on con...  Data Scientist - Entry Level\n",
              "3     a monthcontractunder the general supervisio...                Data Scientist\n",
              "4  location usa xexx multiple locations  years of...                Data Scientist"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lgCZNL_YycP"
      },
      "source": [
        "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PZ8Pj_YxcF",
        "outputId": "bb23551a-fb45-4ab1-9d88-379d05f27b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "vect = CountVectorizer(stop_words='english', min_df=0.02, max_df=0.90, lowercase=True)\n",
        "\n",
        "vect.fit(df1['description'])\n",
        "\n",
        "dtm = vect.transform(df1['description'])\n",
        "\n",
        "dfWords = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
        "\n",
        "dfWords.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ab</th>\n",
              "      <th>abilities</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>academic</th>\n",
              "      <th>accelerate</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accessible</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accommodations</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accordance</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accountability</th>\n",
              "      <th>accounts</th>\n",
              "      <th>accredited</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accurate</th>\n",
              "      <th>achieve</th>\n",
              "      <th>achieving</th>\n",
              "      <th>acquire</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actionable</th>\n",
              "      <th>actions</th>\n",
              "      <th>active</th>\n",
              "      <th>actively</th>\n",
              "      <th>activities</th>\n",
              "      <th>acumen</th>\n",
              "      <th>ad</th>\n",
              "      <th>add</th>\n",
              "      <th>addition</th>\n",
              "      <th>additional</th>\n",
              "      <th>address</th>\n",
              "      <th>addressing</th>\n",
              "      <th>adept</th>\n",
              "      <th>adhoc</th>\n",
              "      <th>...</th>\n",
              "      <th>weve</th>\n",
              "      <th>wexexxre</th>\n",
              "      <th>whatxexxs</th>\n",
              "      <th>wide</th>\n",
              "      <th>wider</th>\n",
              "      <th>willing</th>\n",
              "      <th>willingness</th>\n",
              "      <th>win</th>\n",
              "      <th>women</th>\n",
              "      <th>word</th>\n",
              "      <th>work</th>\n",
              "      <th>worked</th>\n",
              "      <th>workflows</th>\n",
              "      <th>workforce</th>\n",
              "      <th>working</th>\n",
              "      <th>worklife</th>\n",
              "      <th>workload</th>\n",
              "      <th>workplace</th>\n",
              "      <th>works</th>\n",
              "      <th>world</th>\n",
              "      <th>worldclass</th>\n",
              "      <th>worlds</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>worldxexxs</th>\n",
              "      <th>wrangling</th>\n",
              "      <th>write</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>xexx</th>\n",
              "      <th>xexxcbig</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yearsxexx</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>youll</th>\n",
              "      <th>youre</th>\n",
              "      <th>youxexxll</th>\n",
              "      <th>youxexxre</th>\n",
              "      <th>youxexxve</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1834 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ab  abilities  ability  able  ...  youre  youxexxll  youxexxre  youxexxve\n",
              "0   0          0        2     0  ...      0          0          0          0\n",
              "1   0          0        1     0  ...      0          0          0          0\n",
              "2   0          0        1     0  ...      0          0          0          0\n",
              "3   0          0        0     0  ...      0          0          0          0\n",
              "4   0          0        0     0  ...      0          0          0          0\n",
              "\n",
              "[5 rows x 1834 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo1iH_UeY7_n"
      },
      "source": [
        "## 4) Visualize the most common word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5LB00uyZKV5"
      },
      "source": [
        "# create the most common words and the top 10\n",
        "\n",
        "common_words = pd.DataFrame(dfWords.sum().sort_values(ascending=False))\n",
        "\n",
        "common_words.reset_index(inplace=True)\n",
        "\n",
        "common_words.columns=['word', 'count']\n",
        "\n",
        "top_words = common_words.head(10)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY35eByqa1ag",
        "outputId": "5d742f53-17ee-4b6a-e13f-dfeed620cc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Graph the top 10 words\n",
        "plt.style.use('dark_background')\n",
        "plt.figure(figsize=(20, 5))\n",
        "sns.barplot(x=top_words['word'], y=top_words['count']).set_title(\"The Top 10 Words\");"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwFsTqrVZMYi"
      },
      "source": [
        "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gx2gZCbl5Np"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', min_df = 0.2, max_df=0.99, ngram_range=(1,2), lowercase=True)\n",
        "\n",
        "sparse_dtm = tfidf.fit_transform(df1['description'])\n",
        "\n",
        "df2 = pd.DataFrame(sparse_dtm.todense(), columns=tfidf.get_feature_names())"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6_OvA6EblVH",
        "outputId": "97e84e96-9109-47a9-a864-8cdc2e371c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>advanced</th>\n",
              "      <th>age</th>\n",
              "      <th>algorithms</th>\n",
              "      <th>analyses</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analytical</th>\n",
              "      <th>analytics</th>\n",
              "      <th>analyze</th>\n",
              "      <th>andor</th>\n",
              "      <th>applicants</th>\n",
              "      <th>applications</th>\n",
              "      <th>applied</th>\n",
              "      <th>apply</th>\n",
              "      <th>based</th>\n",
              "      <th>benefits</th>\n",
              "      <th>best</th>\n",
              "      <th>better</th>\n",
              "      <th>big</th>\n",
              "      <th>big data</th>\n",
              "      <th>build</th>\n",
              "      <th>building</th>\n",
              "      <th>business</th>\n",
              "      <th>closely</th>\n",
              "      <th>collaborate</th>\n",
              "      <th>color</th>\n",
              "      <th>committed</th>\n",
              "      <th>communicate</th>\n",
              "      <th>communication</th>\n",
              "      <th>communication skills</th>\n",
              "      <th>company</th>\n",
              "      <th>complex</th>\n",
              "      <th>computer</th>\n",
              "      <th>computer science</th>\n",
              "      <th>create</th>\n",
              "      <th>customer</th>\n",
              "      <th>customers</th>\n",
              "      <th>data analysis</th>\n",
              "      <th>data mining</th>\n",
              "      <th>...</th>\n",
              "      <th>solutions</th>\n",
              "      <th>solve</th>\n",
              "      <th>solving</th>\n",
              "      <th>sources</th>\n",
              "      <th>spark</th>\n",
              "      <th>sql</th>\n",
              "      <th>stakeholders</th>\n",
              "      <th>statistical</th>\n",
              "      <th>statistics</th>\n",
              "      <th>status</th>\n",
              "      <th>strong</th>\n",
              "      <th>support</th>\n",
              "      <th>systems</th>\n",
              "      <th>team</th>\n",
              "      <th>teams</th>\n",
              "      <th>technical</th>\n",
              "      <th>techniques</th>\n",
              "      <th>technologies</th>\n",
              "      <th>technology</th>\n",
              "      <th>testing</th>\n",
              "      <th>time</th>\n",
              "      <th>tools</th>\n",
              "      <th>understand</th>\n",
              "      <th>understanding</th>\n",
              "      <th>use</th>\n",
              "      <th>using</th>\n",
              "      <th>value</th>\n",
              "      <th>variety</th>\n",
              "      <th>various</th>\n",
              "      <th>verbal</th>\n",
              "      <th>veteran</th>\n",
              "      <th>veteran status</th>\n",
              "      <th>visualization</th>\n",
              "      <th>way</th>\n",
              "      <th>work</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>written</th>\n",
              "      <th>years</th>\n",
              "      <th>years experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.295921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.212176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.193487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.112122</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.053355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.04663</td>\n",
              "      <td>0.061912</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.354537</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.073858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058488</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069772</td>\n",
              "      <td>0.062640</td>\n",
              "      <td>0.073603</td>\n",
              "      <td>0.059648</td>\n",
              "      <td>0.063762</td>\n",
              "      <td>0.108701</td>\n",
              "      <td>0.115049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074632</td>\n",
              "      <td>0.071874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.075964</td>\n",
              "      <td>0.087475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08387</td>\n",
              "      <td>0.053075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.168421</td>\n",
              "      <td>0.060674</td>\n",
              "      <td>0.173528</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.085267</td>\n",
              "      <td>0.149265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08353</td>\n",
              "      <td>0.161726</td>\n",
              "      <td>0.105873</td>\n",
              "      <td>0.069546</td>\n",
              "      <td>0.075425</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.112852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.14384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.130952</td>\n",
              "      <td>0.111384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.165419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132491</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134864</td>\n",
              "      <td>0.114958</td>\n",
              "      <td>0.121671</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106878</td>\n",
              "      <td>0.108815</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134064</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.180349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185828</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111967</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148078</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.145211</td>\n",
              "      <td>0.319334</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144101</td>\n",
              "      <td>0.138327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.132135</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227547</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118747</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.139337</td>\n",
              "      <td>0.147494</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.145667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.313764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.247427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.314844</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2145</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 226 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    ability  able  advanced  ...   written   years  years experience\n",
              "0  0.295921   0.0  0.000000  ...  0.000000  0.0000               0.0\n",
              "1  0.053355   0.0  0.000000  ...  0.075425  0.0000               0.0\n",
              "2  0.112852   0.0  0.134864  ...  0.000000  0.0000               0.0\n",
              "3  0.000000   0.0  0.000000  ...  0.000000  0.0000               0.0\n",
              "4  0.000000   0.0  0.000000  ...  0.000000  0.2145               0.0\n",
              "\n",
              "[5 rows x 226 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhn54SSRSBKZ"
      },
      "source": [
        "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "8VQowEDMSBKa",
        "outputId": "4d6a6a26-94ba-4b60-ecfa-597bee8a7d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# sets up nearest neighbor parameters\n",
        "n_neighbor = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
        "\n",
        "# fits nearest neighbor model to tfidf vector matrix\n",
        "n_neighbor.fit(df2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi9oBYpvc3O2",
        "outputId": "5779063c-8cb9-4b9e-fdd2-d7b3c339da7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# querys a arbitrary job listing\n",
        "n_neighbor.kneighbors([df2.iloc[10]])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 0.        , 0.95703421, 0.98988007, 1.01940862]]),\n",
              " array([[ 43,  10, 302, 311, 283]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hK5qc_HdCDE",
        "outputId": "757dc6d3-ea24-4b6b-eab7-1e35617a51d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# the same job listing was posted \n",
        "# more than once since this returns true\n",
        "\n",
        "df1['description'][28] == df1['description'][12]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWeB88QZd3VF"
      },
      "source": [
        "job_description = ['''\n",
        "    In search of a entry level data scientist to join a team doing data science! \\n\n",
        "    The ideal candidate will be proficient in python as well as the following python libraries: \\m\n",
        "    pandas, numpy, seaborn, matplotlib, sklearn, and spacy\n",
        "''']\n",
        "\n",
        "job_transformed = tfidf.transform(job_description)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nzbOwcNeIlH",
        "outputId": "1b7ddd9c-f0e6-4d10-c516-23c0ff33fab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# looks for similar job postings\n",
        "\n",
        "n_neighbor.kneighbors(job_transformed.todense())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.10458443, 1.14209807, 1.14244028, 1.16469432, 1.17165091]]),\n",
              " array([[291, 421, 178, 401, 210]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSPtmNeTeSZ6",
        "outputId": "ee00d684-a957-414d-f0f8-589f0b01ddac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "# looks at most similar result\n",
        "\n",
        "df1['description'][421]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'about us want to be part of a fantastic and fun startup thatxexxs revolutionizing the online travel advertising space want to join a data science team thats growing fast and making a big impact on the business come join us at sojern  on the deloitte fast  for five years running sojern applies technology to the travel advertising space delivering b in bookings for the thousands of hotel airline and cruise companies that make up our customer base  the team it is an exciting time to join the data science team at sojern business is booming and the team plays a key role in sojerns mission by automating analyzing modeling and optimizing the way we target potential travelers with the most relevant and timely travel ads  the data science team collaborates with product to define projects analyze data sets and build solutions example projects include   delivering a better understanding of why a traveler books a hotel or flight and utilizing those insights in production models which are used to improve ad relevance timeliness and performance for millions of ads per day analyzing visualizing and improving our ml pipeline that pushes thousands of models into production each month applying ideas from game theory to better understand the value of our audience targeting methods optimizing automated campaign management which allocates budget for over  million display ad impressions daily for over a thousand customers and millions of ad spend per year  as a part of engineering we also drive our solutions to production including   creating data processing jobs using googles big data infrastructure such as bigquery deploying our codebase to production with dockercontainers on google clouds kubernetes platform building and improving internal data science tools like our jupyter server to scale our impact  the role daytoday responsibilities include  collaborating with the team to discover new insights in our unique traveler profile data and utilizing those insights to improve conversion models adding new features to our automated campaign management systems and our ab testing platform mentoring more junior data science engineers by reviewing their code helping them debug and supporting their growth representing the team and its capabilities across the business contributing to our production code base driving additional efficiency and impacting sojerns bottomline  requirements  python proficiency  itxexxs our lingua franca and wexexxre big jupyter fans ms or phd in cs or stem  ability to transform concepts into practical solutions production machine learning experience  successful implementation of ml solutions in production setting communication ability  experiencecomfort in presenting abstract concepts experience as a data scientist   years of experience with data scienceml ad tech experience   years of experience with data scienceml techniques as applied to ad tech specifically experience on fb rtb sem crosschannel attribution crossdevice graph technologies  company culture at sojern culture is king we keep the stress low the dress casual and the work interesting no one is counting your vacation days we trust and encourage our employees to take the time they need we regularly eat out as a team provide the hardware youxexxll need and otherwise let you dig in  recognized on the top company cultures list by entrepreneur magazine sojern is headquartered in san francisco with teams based in dubai dublin hong kong london mexico city new york omaha paris singapore and sydney for more information visit wwwsojerncom  perks  opportunities be part of a growing team with training and support to help you grow ownership lead creative and challenging projects give back we give  hours a year to volunteer and organize office volunteer programs with local organizations culture strong core business values focus on teamwork vibrant social and fun environment snacks variety of snacks in the office meals monthly catered lunches  happy hours wealth stock options time off flexible vacation days  at sojern we value diversity and always treat all employees and job applicants based on merit qualifications competence and talent we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiDfTWceoRkH"
      },
      "source": [
        "## Stretch Goals\n",
        "\n",
        " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
        " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
        " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
        " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
        "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
        " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
      ]
    }
  ]
}